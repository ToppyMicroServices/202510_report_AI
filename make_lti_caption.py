#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
make_lti_caption.py
- Read LTI_summary_stats.csv and emit TeX macros for figure captions.

Default IO:
  input:  LTI_summary_stats.csv
  output: Tables/lti_caption_numbers.tex

Usage:
  python make_lti_caption.py
  python make_lti_caption.py --csv LTI_summary_stats.csv --out Tables/lti_caption_numbers.tex
"""

import argparse
import csv
from pathlib import Path
from decimal import Decimal, InvalidOperation
import sys
import re


def fmt(x, digits=3, pct=False):
    """Format numbers with fixed digits using Decimal (no scientific notation).
    If pct=True, keep the numeric text but do not append a % here â€” TeX symbol is handled later.
    Returns empty string for None/empty inputs.
    """
    if x is None:
        return ""
    s = str(x).strip()
    if s == "":
        return ""
    try:
        d = Decimal(s)
    except (InvalidOperation, ValueError):
        # Not a number; return as-is (e.g., already formatted text)
        return s
    q = Decimal(1).scaleb(-digits)  # 10**(-digits)
    return f"{d.quantize(q)}"


def main():
    ap = argparse.ArgumentParser(description="Generate TeX macros for LTI caption from CSV")
    ap.add_argument("--csv", default="LTI_summary_stats.csv", help="Input CSV path")
    ap.add_argument("--out", default="Tables/lti_caption_numbers.tex", help="Output TeX macro file")
    ap.add_argument("--digits-r", type=int, default=3, help="Digits for correlations")
    ap.add_argument("--digits-slope", type=int, default=3, help="Digits for slopes")
    ap.add_argument("--digits-pct", type=int, default=1, help="Digits for percent diffs")
    ap.add_argument("--percent-sign", action="store_true", help="Append \\% to percent diff macros")
    ap.add_argument("--ci-brackets", default="[]", choices=["[]","()","{}"], help="Bracket style for CI macros")
    args = ap.parse_args()

    csv_path = Path(args.csv)
    if not csv_path.exists():
        raise SystemExit(f"Input CSV not found: {csv_path}")

    with csv_path.open(newline='', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        row = None
        for r in reader:
            # pick the first non-empty row
            if any((str(v).strip() if v is not None else "") for v in r.values()):
                row = r
                break
        if row is None:
            raise SystemExit("Input CSV is empty")

    # Pull required fields with fallbacks
    def get(key, default=""):
        return row.get(key, default)

    def warn(msg):
        print(f"[warn] {msg}", file=sys.stderr)

    def is_num(s):
        try:
            Decimal(str(s))
            return True
        except Exception:
            return False

    # Correlations (NIS)
    pearson = fmt(get('pearson_NIS'), args.digits_r)
    pearson_lo = fmt(get('pearson_NIS_CI_lo'), args.digits_r)
    pearson_hi = fmt(get('pearson_NIS_CI_hi'), args.digits_r)
    spearman = fmt(get('spearman_NIS'), args.digits_r)

    # Slopes (NIS)
    ts_slope = fmt(get('TS_slope_NIS'), args.digits_slope)
    ts_slope_lo = fmt(get('TS_slope_NIS_CI_lo'), args.digits_slope)
    ts_slope_hi = fmt(get('TS_slope_NIS_CI_hi'), args.digits_slope)
    ols_slope = fmt(get('OLS_slope_NIS'), args.digits_slope)
    pct_diff_val = fmt(get('OLS_vs_TS_slope_diff_pct_NIS'), args.digits_pct, pct=True)

    # Optional (tail NIS_q), in case needed elsewhere
    pearson_q = fmt(get('pearson_NISq'), args.digits_r) if get('pearson_NISq') != '' else ''
    spearman_q = fmt(get('spearman_NISq'), args.digits_r) if get('spearman_NISq') != '' else ''
    ts_slope_q = fmt(get('TS_slope_NIS_q'), args.digits_slope) if get('TS_slope_NIS_q') != '' else ''

    # Build CI strings with chosen brackets
    L, R = ("[", "]") if args.ci_brackets == "[]" else (("(", ")") if args.ci_brackets == "()" else ("{", "}"))
    pearson_ci = f"{L}{pearson_lo}, {pearson_hi}{R}" if pearson_lo and pearson_hi else ""
    ts_slope_ci = f"{L}{ts_slope_lo}, {ts_slope_hi}{R}" if ts_slope_lo and ts_slope_hi else ""

    # Sanity checks (non-fatal)
    if pearson and is_num(pearson):
        try:
            v = float(pearson)
            if not (-1.0 <= v <= 1.0):
                warn(f"pearson_NIS={pearson} is outside [-1,1]")
        except Exception:
            pass

    out_path = Path(args.out)
    if out_path.parent and not out_path.parent.exists():
        out_path.parent.mkdir(parents=True, exist_ok=True)

    lines = []
    lines.append("% Auto-generated by make_lti_caption.py; do not edit manually.")
    lines.append("% Source: " + str(csv_path.resolve()))

    def emit(name: str, val: str) -> None:
        # Always define the macro, even if val is empty
        lines.append(f"\\newcommand{{\\{name}}}{{{val}}}")

    # Core correlations (always emit)
    emit("LTIPearsonNIS", pearson)
    emit("LTIPearsonNISLo", pearson_lo)
    emit("LTIPearsonNISHi", pearson_hi)
    emit("LTIPearsonNISCI", pearson_ci)  # may be empty
    emit("LTISpearmanNIS", spearman)

    # Slopes (always emit)
    emit("LTITSSlopeNIS", ts_slope)
    emit("LTITSSlopeNISLo", ts_slope_lo)
    emit("LTITSSlopeNISHi", ts_slope_hi)
    emit("LTITSSlopeNISCI", ts_slope_ci)  # may be empty
    emit("LTIOLSSlopeNIS", ols_slope)

    # Percent diff macro (always emit). If value exists and --percent-sign given, append \%.
    if pct_diff_val:
        pct_text = pct_diff_val + ("\\%" if args.percent_sign else "")
    else:
        pct_text = ""
    emit("LTIOLSTSDiffPctNIS", pct_text)

    # Optional q-variants (always emit, even if empty)
    emit("LTIPearsonNISq", pearson_q)
    emit("LTISpearmanNISq", spearman_q)
    emit("LTITSSlopeNISq", ts_slope_q)

    out_path.write_text("\n".join(lines) + "\n", encoding='utf-8')
    print(f"[ok] wrote TeX macros: {out_path}")
    print("[summary] ", {
        "pearson": pearson,
        "pearson_CI": pearson_ci,
        "spearman": spearman,
        "TS_slope": ts_slope,
        "TS_CI": ts_slope_ci,
        "OLS_slope": ols_slope,
        "OLS_vs_TS_diff_pct": (pct_diff_val + ("%" if args.percent_sign and pct_diff_val else ""))
    })

    # --- Best-effort: wrap & slim Tables/tab_paired_deltas.tex ---
    paired_path = Path("Tables/tab_paired_deltas.tex")
    try:
        if not paired_path.exists():
            print(f"[info] {paired_path} not found; skipping wrap/slim.")
        else:
            txt = paired_path.read_text(encoding="utf-8")

            # 1) Wrap the first tabular/tabular* with \resizebox if not already wrapped
            already_wrapped = r"\resizebox{\textwidth}{!}{" in txt
            if not already_wrapped:
                pattern_star  = re.compile(r"(\\begin\\{tabular\\*\\}\\{[^}]+\\}\\s*\\{[^}]+\\})([\\s\\S]*?)(\\end\\{tabular\\*\\})", re.M)
                pattern_plain = re.compile(r"(\\begin\\{tabular\\}\\{[^}]+\\})([\\s\\S]*?)(\\end\\{tabular\\})", re.M)
                m = pattern_star.search(txt) or pattern_plain.search(txt)
                if m:
                    txt = (
                        txt[:m.start()]
                        + "\\resizebox{\\textwidth}{!}{%\n"
                        + m.group(1) + m.group(2) + m.group(3)
                        + "\n}% <-- ensure closure"
                        + "\n" + txt[m.end():]
                    )
                    paired_path.write_text(txt, encoding="utf-8")
                    print(f"[ok] wrapped: {paired_path}")
                else:
                    print(f"[warn] No tabular or tabular* environment found in {paired_path}; no wrapping applied.")

            # 2) Slim columns: drop first two (model, prompt)
            txt2 = paired_path.read_text(encoding="utf-8")

            # Find begin/end of (possibly wrapped) tabular or tabular*
            tbeg = re.search(r"\\begin\\{tabular\\*?\\}\\{([^}]*)\\}", txt2)
            tend = re.search(r"\\end\\{tabular\\*?\\}", txt2)
            if tbeg and tend and tbeg.start() < tend.start():
                align_spec = tbeg.group(1)

                # Remove first two *real* column specs: l/c/r/S or p{..}. Keep | and @{} as-is.
                def drop_two_cols(spec: str) -> str:
                    out = []
                    i, removed = 0, 0
                    L = len(spec)
                    while i < L:
                        # skip spaces
                        if spec[i].isspace():
                            out.append(spec[i]); i += 1; continue
                        # structural tokens (| or @{})
                        if spec[i] == '|':
                            out.append(spec[i]); i += 1; continue
                        if spec.startswith("@{", i):
                            j = i + 2; depth = 1
                            while j < L and depth > 0:
                                if spec[j] == '{': depth += 1
                                elif spec[j] == '}': depth -= 1
                                j += 1
                            out.append(spec[i:j]); i = j; continue
                        # real column specs to potentially remove
                        if removed < 2 and spec[i] in "lcrS":
                            removed += 1; i += 1; continue
                        if removed < 2 and spec.startswith("p{", i):
                            j = i + 2; depth = 1
                            while j < L and depth > 0:
                                if spec[j] == '{': depth += 1
                                elif spec[j] == '}': depth -= 1
                                j += 1
                            removed += 1; i = j; continue
                        # default: keep
                        out.append(spec[i]); i += 1
                    return "".join(out)

                new_spec = drop_two_cols(align_spec)

                # Replace the alignment spec in the \begin{tabular...}{...}
                txt2 = txt2[:tbeg.start()] + re.sub(r"\\begin\\{tabular\\*?\\}\\{[^}]*\\}",
                                                    f"\\\\begin{{tabular}}{{{new_spec}}}",
                                                    txt2[tbeg.start():], count=1)

                # Now drop the first two cells from each row within the tabular body
                body_start = tbeg.end()
                body_end   = tend.start()
                body = txt2[body_start:body_end]
                lines = body.splitlines()
                new_lines = []
                for ln in lines:
                    stripped = ln.strip()
                    # keep rule lines intact
                    if stripped.startswith(("\\toprule", "\\midrule", "\\bottomrule")):
                        new_lines.append(ln); continue
                    # non-row lines
                    if "&" not in ln:
                        new_lines.append(ln); continue
                    # split cells, preserve trailing \\\\ and comments
                    mrow = re.match(r"^(.*?)(\\\\.*)?\\s*$", ln)
                    if not mrow:
                        new_lines.append(ln); continue
                    cells_part = mrow.group(1)
                    trail = mrow.group(2) or ""
                    cells = [c.strip() for c in cells_part.split("&")]
                    if len(cells) >= 3:
                        cells = cells[2:]  # drop (model, prompt)
                        ln = " & ".join(cells) + trail
                    new_lines.append(ln)

                new_body = "\n".join(new_lines)
                txt2 = txt2[:body_start] + new_body + txt2[body_end:]
                paired_path.write_text(txt2, encoding="utf-8")
                print(f"[ok] slimmed columns (dropped model/prompt): {paired_path}")
            else:
                print(f"[warn] Could not locate tabular block for slimming in {paired_path}.")
    except Exception as e:
        print(f"[warn] Failed to wrap/slim {paired_path}: {e}")



if __name__ == "__main__":
    main()
